% !Mode:: "TeX:UTF-8"

\hitsetup{
  %******************************
  % 注意：
  %   1. 配置里面不要出现空行
  %   2. 不需要的配置信息可以删除
  %******************************
  %
  %=====
  % 秘级
  %=====
  statesecrets={公开},
  natclassifiedindex={TM301.2},
  intclassifiedindex={62-5},
  %
  %=========
  % 中文信息
  %=========
  %ctitleone={局部多孔质气体静压},%本科生封面使用
  %ctitletwo={轴承关键技术的研究},%本科生封面使用
  ctitlecover={基于深度学习的中文语义依存图\\分析技术研究},%放在封面中使用，自由断行
  ctitle={局部多孔质气体静压轴承关键技术的研究},%放在原创性声明中使用
  %csubtitle={一条副标题}, %一般情况没有，可以注释掉
  cxueke={工学},
  csubject={计算机科学与技术},
  caffil={计算机科学与技术学院},
  cauthor={王宇轩},
  csupervisor={车万翔教授},
  %cassosupervisor={某某某教授}, % 副指导老师
  %ccosupervisor={某某某教授}, % 联合指导老师
  % 日期自动使用当前时间，若需指定按如下方式修改：
  cdate={2021年8月},
  cstudentid={16B903007},
  cstudenttype={学术学位论文}, %非全日制教育申请学位者
  cnumber={no9527}, %编号
  %cpositionname={哈铁西站}, %博士后站名称
  %cfinishdate={20XX年X月---20XX年X月}, %到站日期
  %csubmitdate={20XX年X月}, %出站日期
  %cstartdate={3050年9月10日}, %到站日期
  %cenddate={3090年10月10日}, %出站日期
  %（同等学力人员）、（工程硕士）、（工商管理硕士）、
  %（高级管理人员工商管理硕士）、（公共管理硕士）、（中职教师）、（高校教师）等
  %
  %
  %=========
  % 英文信息
  %=========
  etitle={Chinese Semantic Dependency Graph Parsing Based on Deep Learning},
  %esubtitle={This is the sub title},
  exueke={Engineering},
  esubject={Computer Science and Technology},
  eaffil={\emultiline[t]{School of Computer Science \\ and Technology}},
  eauthor={Yuxuan Wang},
  esupervisor={Professor Wanxiang Che},
  %eassosupervisor={XXX},
  % 日期自动生成，若需指定按如下方式修改：
  edate={August, 2021},
  %estudenttype={Master of Art},
  %
  % 关键词用“英文逗号”分割
  ckeywords={语义依存图分析, 对抗样本攻击, 鲁棒性, 多语言, 图神经网络},
  ekeywords={Semantic Dependency Graph Parsing, Adversarial Attack, Robustness, Multilingual Learning, Graph Neural Network},
}

\begin{cabstract}

%自然语言处理是人工智能的重要子学科。
让机器理解自然语言，是自然语言处理领域最根本也是最重要的问题之一。
要实现在语义层面上理解自然语言，一般来说需要对原始文本自底向上进行分词、词性标注、命名实体识别、句法分析，最后才能进行语义分析。
然而，由于中文严重缺乏形态变化，词类与句法成分没有严格的对应关系，导致中文句法分析的精度始终不高。
此外，近年来人们发现传统句法分析中的树结构已经无法胜任刻画句子中复杂的语义关系的任务，研究者们逐渐将目光聚集到约束更少的图结构上，希望用图结构来表示这些语义关系。
因此，语义依存图分析应运而生，它通过在句子结构中分析实词间的语义关系来回答句子中“谁在何时何地对谁做了什么”等问题。

语义依存图分析建立在依存理论基础上，是对语义的深层分析，具有形式简洁，易于理解和运用的优势。
与传统的句法分析不同，语义依存图分析可以跨越句子的表层结构直接获取深层语义表达的本质，因此能为机器翻译、问答系统、信息抽取等对语义信息要求较高的自然语言处理任务提供很大帮助。
图结构的引入，在带来更全面的语义表示的同时，也给语义依存图分析任务带来了巨大的挑战。
作为一个新兴课题，无论是语义依存图的基础分析方法还是其在其他任务上的应用都有待探究。

本文围绕中文语义依存图分析技术及其应用，开展了以下四个方面的研究：

\textbf{1.基于深度学习的语义依存图分析：}  
针对语义依存图的图结构特性，本文利用基于转移的分析方法，设计了适用于图结构的转移系统。
同时提出一种基于栈-长短时记忆网络的分类器，利用当前转移状态预测下一步转移动作，从而实现了对语义依存图的自动分析。
%使用了两种新的神经网络模块（Incremental Tree-LSTM和Bi-LSTM Subtraction）对转移系统中十分重要的子图和缓存部分进行建模，

\textbf{2.基于对抗样本的依存分析器鲁棒性研究：}
尽管基于深度学习的依存分析器在规范的文本组成的语料库上获得了较好的性能，其在非规范文本上的性能却有显著下降。
针对这一问题，本文设计了对抗样本攻击框架用于生成使分析器产生误判的非规范文本，并利用此框架对基于深度学习的依存分析器的鲁棒性进行深入探究。
本文进一步提出模型融合和对抗样本训练方法，有效提升了基于深度学习的依存分析器的鲁棒性。
%我们通过设计攻击算法生成对抗样本的方法，针对基于神经网络的依存分析器中的这一现象进行研究，分析了该任务中对抗样本的特性，并提出了增强分析器鲁棒性的方法。

\textbf{3.跨语言语义依存图分析：}
目前语义依存图分析的研究主要集中在少数几种语言上，而对于世界上绝大部分语言，语义依存图标注难以获取，且人工标注代价高。
针对这一问题，本文提出基于标签转换和图神经网络的自动标注转化方法，通过构建伪数据、训练神经网络转化器，将大量现有的多语言依存句法标注转化为语义依存图标注。
进而利用这些自动转化的依存图标注和跨语言上下文相关词向量训练分析器，实现对资源稀缺语言的语义依存图分析。

\textbf{4.基于图神经网络的语义依存图应用：}
目前几乎所有语义依存图相关研究都集中在数据集构建和自动分析器设计上。
但作为一条理解自然语言的途径，语义依存图分析的最终目的是在语义层面帮助其他任务。
本文提出一个基于图神经网络的模型，将语义依存图中的信息有效融入预训练模型中，并将此强化的预训练模型应用于其他任务中，有效提升了其性能。

总的来说，本文从中文语义依存图分析方法本身开始，深入探究了在非规范文本和多语言文本中的依存图分析技术，最终将语义依存图中的信息融入预训练模型并将其应用于其他自然语言处理任务，从而显著提升了他们的性能。
本文的研究证明了中文语义依存图能为其他自然语言处理任务提供有效帮助，并为此建立了一套通用框架。
我们期待本文的研究成果能进一步拓展至更多的自然语言处理任务，从而进一步推进该领域的发展。

\end{cabstract}

\begin{eabstract}

Natural language understanding (NLP) is one of the most fundamental and most significant problems in Natural Language Processing. 
Conventionally, the understanding of natural language is a bottom-up process including word segmentation, part-of-speech tagging, named entity recognition, syntactic parsing, and eventually semantic analysis. 
However, as a morphologically poor language, Chinese syntactic parsing performance has always been lower than other morphologically rich languages. 
Additionally, conventional tree-structured annotation used in syntactic parsing has shown its incapability in capturing complicated semantic relations in a sentence. 
Therefore, graph-structured semantic annotation is receiving growing interest in recent years. 
Semantic dependency graph parsing aims at analysing semantic relations between words in a sentence and answers the questions "who did what to whom when and where". 

Semantic dependency graph parsing is based on dependency theory and has the advantages of easy to understand and use. 
Compared to conventional syntactic parsing, semantic dependency graph parsing reveals the deep semantic meaning of a sentence, and thus is helpful for NLP tasks that require semantic information, such as machine translation, question answering and information extraction. 
The introduction of graph structure has improved the ability to capture complicated semantic relations. 
It also makes the parsing of semantic dependency graph more challenging. 
As an emerging task, both the parsing approach and the application method of semantic dependency graph are yet to be explored. 

This paper focus on the parsing approach and application method of Chinese semantic dependency graph and conduct research on the following four directions: 

\textbf{1.\ Semantic dependency graph parsing based on deep learning:} 
We propose to parse semantic dependency graph with a transition-based method and design a transition system for graph parsing. 
Besides, we propose a neural classifier based on Stack-LSTM, which predicts the next transition action based on the current transition state. 

\textbf{2.\ Research on dependency parsers' robustness based on adversarial attacks:} 
Although neural dependency parsers achieve fair results on datasets consisting of formal texts, its performance is much lower when applied to informal texts. 
We propose an adversarial attack framework that generates adversarial examples and explore the robustness of neural dependency parsers with it. 
We further propose to improve the neural parsers' performance by model ensembling and adversarial training. 

\textbf{3.\ Cross-lingual semantic dependency graph parsing:} 
Existing research on semantic dependency graph parsing mainly focused on several languages. 
However, semantic dependency graph annotation is hard to obtain for most of languages in the world. 
And the manual annotation is extremely expensive. 
Therefore, we propose an approach based on label switching and graph neural network which automatically converts existing multilingual universal syntactic dependency annotation to semantic dependency graph annotation. 
Using the automatically converted annotation and cross-lingual contextual embeddings, we train cross-lingual semantic dependency parser that effectively parses low-resource languages. 

\textbf{4.\ Semantic dependency graph application based on graph neural networks:} 
Existing research on semantic dependency graph parsing mostly focused on the construction of dataset and parsing model. 
However, the eventual goal of semantic dependency graph parsing is to help other NLP tasks semantically. 
We propose a graph neural network-based model, which effectively incorporate semantic information from semantic dependency graphs into pre-trained models. 
The enhanced pre-trained model is used on other NLP tasks, whose results are significantly improved. 

Overall, this paper starts at building Chinese semantic dependency graph parsing, and explores the parsing techniques on informal texts and multilingual texts. 
Eventually, the semantic information in semantic dependency graph is incorporated into pre-trained models and thus helps to improve the performance on other NLP tasks. 
Our research verifies that Chinese semantic dependency graph can effectively help other NLP tasks and proposes a unified framework for the purpose. 
In the future, we expect to apply our research to more NLP tasks, thus promoting the development of the NLP field. 


\end{eabstract}
