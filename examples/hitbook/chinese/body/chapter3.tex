% !Mode:: "TeX:UTF-8"

\chapter[非规范文本语义依存图分析]{非规范文本语义依存图分析}[Semantic Dependency Graph Parsing on Informal Texts]

\section{引言}[Introduction]
\label{sec:chapter3-intro}

神经网络在自然语言处理领域的应用，不仅解决了传统的基于特征工程的统计学习模型中对专家知识的依赖，更有效提升了该领域各个任务上模型的性能\cite{chen-manning-2014-fast,chiu-nichols-2016-named,ma-hovy-2016-end,zhou-etal-2016-text,chopra-etal-2016-abstractive}。
随着2018年BERT模型的提出，以其为代表的预训练模型为自然语言处理领域带来了新一波的显著性能提升\cite{peters-etal-2018-deep,devlin-etal-2018-bert,yang-etal-2019-xlnet,clark-etal-2020-electra}。
然而，尽管在自然语言处理领域中的很多数据集上，神经网络模型已经取得了接近甚至超过人类的效果，但近期的研究表明，现有的神经网络模型鲁棒性很弱。
与其在规范文本组成的数据集上取得的成功相对应的是其在非规范文本上性能的大幅下降\cite{alzantot-etal-2018-generating, ren-etal-2019-generating, cheng-etal-2019-robust,michel-etal-2019-evaluation, jin-etal-2020-isbert}。

对神经网络模型的鲁棒性进行研究的一般方式是对抗样本攻击（adversarial attack），即设计算法针对特定的目标模型（target model或victim model）生成使其产生误判的非规范文本。
这种文本被称为对抗样本（adversarial example）。
目前自然语言处理领域的鲁棒性研究工作一般选择情感分类、文本蕴涵等文本分类任务作为目标任务。
针对这些任务的特点，高质量的对抗样本需要满足两个条件：（1）在语义上与原始文本相同；（2）对原始文本的修改难以被察觉。
其中第一点的作用是保证在有标注数据上，修改后的对抗样本的类别不会因修改而改变，这样才能利用原始本文上的标注信息对攻击算法的性能进行评价。
而第二点从另一个角度来说，就是要保持对抗样本的流畅性，使得人类不会因文本的修改而对其类别产生误判。
因为使人类也产生误判的对抗样本对于模型的鲁棒性研究来说毫无作用，其可能就是完全无意义的词语组合。

尽管目前已有不少研究者针对上述以分类任务上神经网络模型的鲁棒性开展研究，但很少有人研究句法依存分析和语义依存图分析等结构化预测任务上的神经网络模型鲁棒性。
虽然这类任务无法直接应用到日常生活中，但其预测结果往往被用于帮助其他能直接应用的任务。
而一旦其性能因为非规范文本而显著下降，错误级联效应会导致使用其输出的其他任务模型性能也受到影响。

此前虽然有少量针对句法依存分析模型鲁棒性的研究工作，但其往往只注重攻击算法本身，而采用了简单的候选词生成方法，从而影响了生成的对抗样本的质量。
针对这一问题，本章首先设计了一套针对基于神经网络的依存分析模型的攻击算法，使用了多种候选词生成方法生成大量候选词，接着使用多种过滤方法将其中不合适的过滤掉，从而保证了候选词的质量和数量，最终实现了高质量对抗样本的生成。
接着，本章借助该对抗样本攻击算法对现存的多种依存分析模型和词向量的组合进行了攻击，并设计了多项实验研究基于神经网络的依存分析模型的鲁棒性。
最后，依据在分析实验中的发现，本章提出两种提升现有基于神经网络的依存分析模型鲁棒性的方法，分别是对抗样本训练（adversarial training）和模型融合。

为了验证上述对抗样本攻击算法的有效性，本章分别在中文语义依存图分析任务和英文句法分析任务上进行了实验，并组织了针对对抗样本质量的人工评测。
结果表明上述方法有效提升了生成的对抗样本的质量，而对抗样本训练和模型融合都能有效提高现有的基于神经网络的依存分析模型的鲁棒性。

\section{背景与相关工作}[Related Work]
\label{sec:chapter3-related-work}
与重视语义的分类任务不同，在依存分析等结构化预测任务上，高质量的对抗样本需要满足两个条件：（1）语义或句法结构与原始文本相同；（2）文本流畅性。
其中第二点与分类任务中的条件相同，也是为了保证对抗样本不使人类产生误判。
而第一点则是为了保证原始文本上的人工标注信息在对抗样本上依然有效，这与分类任务中第一个条件有类似之处，但对于结构化预测任务更为严格。
这是因为首先结构化预测任务上的标注信息不仅只有一个标签，而是一个复杂的结构。
其次，相比于分类任务，结构化预测任务的标注更难以获取。
要使用正确的标注信息对攻击算法进行评价，往往只能保证修改后的文本上的结构不变。
正如第\ref{sec:chapter3-intro}节所介绍，目前虽然有少量针对句法依存分析模型鲁棒性的研究工作，但其往往忽略了对抗样本的质量。
本节将重点介绍与本章研究内容密切相关的针对依存分析模型鲁棒性进行研究的工作。

Zheng等人\cite{zheng-etal-2020-evaluating}于2020年在英文上首次开展了针对基于神经网络的句法依存分析模型的鲁棒性研究。
他们使用BERT模型基于上下文预测每个词的候选词，然后选择使目标模型性能下降最大的候选词替换原始文本中的词，从而实现对句法依存分析器的攻击。
具体来说，本文第\ref{sec:chapter1-informal}节已经介绍了BERT使用的遮盖语言模型训练目标，即通过将目标词遮盖然后用其上下文预测该词。
而该方法依次将目标句子中的每个词用BERT模型中特殊的遮盖符号进行替换，然后用BERT模型对该词进行预测，从而获取BERT模型词表中所有词在文本中该位置出现的概率。
然后再对这些词按照出现概率进行排序，选取其中前$N$个作为候选词。
需要特别说明的是，由于英文BERT模型使用的是词片段（word piece）向量而非词向量，其词表中很多都是不完整的词片段而非整词。
而不完整的词片段显然是无法替代原始句子中完整的词的，因此该方法只选择出现概率高的候选词中的整词作为候选词。
显然这种方法严重限制了候选词的多样性，而且由于英文中大部分复杂的词在BERT中都会被切割成词片段，这种方法无法生成这些复杂的词。

Han等人\cite{han-etal-2020-adversarial}于2020年在英文上开展了针对结构化预测任务上的神经网络模型的鲁棒性研究，并在句法依存分析任务上进行了实验。
他们提出一个序列到序列（sequence-to-sequence）模型，根据输入的原始文本生成对抗样本。
由于该模型无法保证生成的对抗样本与原始文本长度相同或具有相同的结构，该方法使用了两个额外的依存分析器的预测结果作为参考。
这两个额外的依存分析器与目标依存分析器要求是两两不同的依存分析模型，这样才能保证其预测结果与受攻击的目标分析器不同，且两个参考依存分析器之间才能互相验证。
该方法对于目标分析器和参考分析器的类别有较严格的要求，而且尽管其通过限制分析器类别提升了作为参考的预测结果的准确性，该方法仍然无法保证预测结果是完全正确的。
在这种情况下，使用预测的结果作为对抗样本正确标注对攻击方法进行评估也难以保证其准确率。

总的来说，此前的针对基于神经网络的依存分析模型的鲁棒性研究集中在英文的句法依存分析任务上，且往往忽略了生成的对抗样本质量。
而在对抗样本攻击中，对抗样本的质量是十分重要的，低质量的对抗样本很可能使人类也产生误判，从而对于模型鲁棒性的研究没有贡献。
另外，在对模型鲁棒性研究的基础上，如何提升依存分析模型的鲁棒性，也是亟待解决的问题。
因此，本章首先设计了针对依存分析模型生成高质量对抗样本的攻击算法，然后利用该算法对现有的依存分析模型鲁棒性进行研究，并在此基础上提出了提升其鲁棒性的方法。

\section{针对依存分析器的对抗样本攻击算法}[Adversarial Attacking Framework against Dependency Parsers]

正如本文第\ref{sec:chapter1-informal}中所介绍的，根据攻击者对被攻击模型的了解程度，对抗样本攻击可以分为白盒攻击和黑盒攻击两类。
在白盒攻击情境下，攻击者能获取目标系统的所有信息，包括模型结构，参数及权重值等。
而在黑盒攻击情境下，攻击者仅能用对目标系统查询的方式，通过输入观察输出结果。
显然在现实应用场景中，白盒攻击的条件是很难达成的。
因此本章选择更贴近现实应用场景的黑盒攻击情境，设计了一个针对依存分析模型的黑盒攻击算法，生成高质量的对抗样本。

%研究表明，在深度神经网络输入中加入微小扰动信息，能够使其产生误判。
%这种使神经网络产生误判的攻击称为对抗样本攻击，其中使用的输入样本称为对抗样本。
%尽管基于深度神经网络的模型在自然语言处理领域的很多任务上都取得了很好的成果，但对抗样本攻击揭示了这类模型脆弱的一面。
%为了提高现有依存分析器的鲁棒性，使其适用于现实复杂场景，我们首先设计对抗样本攻击算法，针对现有各类依存分析器生成对抗样本，并对生成的样本进行分析，在此基础上提出了增强分析器鲁棒性的方法。

\iffalse
这里我们
图~\ref{fig:adv-example}展示了一个我们的攻击算法生成的对抗样本，其中上半部分为原始文本及正确的依存句法预测结果，下半部分为我们生成的对抗样本及目标分析器预测结果（红色部分表示预测错误的依存弧和标签）。
在该实例中，我们的攻击算法只修改了一个词（将highway改为superhighway），就使得目标分析器产生了5个错误。

\begin{figure}[htbp]
	\centering
	\begin{dependency}[theme = simple,label style={font=\bfseries}]
		\begin{deptext}[column sep=0.45em]
			A\& bus\& is\& the\& data\& \textcolor{green}{highway}\& within\& a\& computer \\ %\& . \\
			A\& bus\& is\& the\& data\& \textcolor{red}{\textit{\textbf{superhighway}}}\& within\& a\& computer \\%\& . \\
		\end{deptext}
		\deproot{6}{root}
		\depedge{2}{1}{det}
		\depedge{6}{2}{nsubj}
		\depedge{6}{3}{cop}
		\depedge{6}{4}{det}
		\depedge{6}{5}{nn}
		\depedge{6}{7}{prep}
		\depedge{9}{8}{det}
		\depedge{7}{9}{pobj}
		%\depedge{6}{10}{punct}
		
		\deproot[edge below, dashed, edge style={red}, label style={below, font=\bfseries, text=red}]{5}{\textit{root}}
		\depedge[edge below, label style={below}]{2}{1}{det}
		\depedge[edge below, dashed, edge style={red}, label style={below, font=\bfseries, text=red}]{5}{2}{nsubj}
		\depedge[edge below, dashed, edge style={red}, label style={below, font=\bfseries, text=red}]{5}{3}{cop}
		\depedge[edge below, dashed, edge style={red}, label style={below, font=\bfseries, text=red}]{5}{4}{det}
		\depedge[edge below, dashed, edge style={red}, label style={below, font=\bfseries, text=red}]{5}{6}{\textit{partmod}}
		\depedge[edge below, label style={below}]{6}{7}{prep}
		\depedge[edge below, label style={below}]{9}{8}{det}
		\depedge[edge below, label style={below}]{7}{9}{pobj}
		%\depedge[edge below, dashed, edge style={red}, label style={below, font=\bfseries, text=red}]{5}{10}{\textit{punct}}
	\end{dependency}
	\bicaption[fig:adv-example]{}{对抗样本实例}{Fig.$\!$}{Example of an adversarial example.}
\end{figure}
\fi

下面首先给出针对依存分析模型进行对抗样本攻击的形式化定义。
给定包括所有可能输入句子$\bm{x}$的输入文本空间$\mathcal{X}$和包括$\bm{x}$所有可能依存结构的输出空间$\mathcal{Y}$。
一个依存分析模型$F: \mathcal{X} \rightarrow \mathcal{Y}$的目标是学习一个从输入句子$\bm{x}$到其对应依存结构$\bm{y}$的映射，记为$F(\bm{x}) = \bm{y}$。
句子$\bm{x}$中的第$i$个词记为$x_i$，用$(i,j,r) \in \bm{y}$表示依存结构$\bm{y}$中存在一条由$x_i$指向$x_j$，标签为$r$的弧。

给定一个句子$\bm{x}$，本章通过对其进行微小的修改获得$\bm{x}^*$，当$\bm{x}^*$满足以下条件时，将其称为一个有效的对抗样本：
$$F(\bm{x}^*) \neq \bm{y}, \sigma(\bm{x}^*, \bm{x})\le \epsilon, $$
其中$\sigma$为样本变化约束函数，$\epsilon$则限制了生成的对抗样本$\bm{x}^*$需要满足两个条件：（1）对抗样本相对于原始文本的变化足够小；（2）对抗样本的正确依存结构与原始文本的正确依存结构相同。
这两个条件是第\ref{sec:chapter3-related-work}中提出的结构化预测任务上高质量对抗样本需要满足的条件在对抗样本攻击中的具体体现。
在本章提出的方法中，通过使用多种候选词生成方法和多种候选词过滤方法来确保他们。
在实验中，本章将分别采用流畅性和依存结构不变性两个评价指标对生成的对抗样本是否满足这两个条件进行评价。

本章提出的针对依存分析模型的黑盒攻击算法如算法~\ref{algo:attack}所示，由词重要性排序（1-4行）、候选词生成（第7行）和替换词搜索（8-28行）三部分组成。
其核心思想是对句中每个词生成若干能保证流畅性和依存结构不变性的候选词，按照句中词的重要性由高到低搜索并替换能使目标分析模型预测准确率下降的候选词。
接下来对这三个部分进行具体介绍。

\begin{algorithm}[!h]
    \wuhao
	%\begin{flushleft}
	%	\textbf{Input:} 原始样本 $\bm{x}^{(0)}=\{x_1,x_2,\dots,x_N\}$, 最大允许修改百分比 $\gamma$ \\
	%	\textbf{Output:} 对抗样本 $\bm{x}^{(i)}$
	%\end{flushleft}
	\LinesNumbered %要求显示行号
    \KwIn{原始样本 $\bm{x}^{(0)}=\{x_1,x_2,\dots,x_N\}$, 最大允许修改百分比 $\gamma$}%输入参数
    \KwOut{对抗样本 $\bm{x}^{(i)}$}%输出
		\For{$i=1$ to $N$}
		{
		    用公式~\ref{eq:word-importance}计算词重要性$I(\bm{x}^{(0)},x_i)$\;
		}
		建立一个由$x_i\in\bm{x}^{(0)}$组成的集合$W$，其中词按照重要性$I(\bm{x}^{(0)},x_i)$从高到低排序\;
		$t=0$\;
		\For{$W$中每个$x_j$}
		{
		    按照候选词生成步骤建立词$x_j$的候选词集合$\mathcal{C}_j$\;
		    初始化有效候选词集合$\mathcal{VC} \leftarrow \{\}$\;
		    \For{$\mathcal{C}_j$中每个候选词$c_k$}
		    {
		        用公式~\ref{eq:mis-inc}计算准确率改变量$S(\bm{x}^{(t)},c_k,j)$\;
		        \If{$S(\bm{x}^{(t)},c_k,j) > 0$}
		        {
		            将$c_k$加入集合$\mathcal{VC}$
		        }
		        %\algorithmicif\  $S(\bm{x}^{(t)},c_k,j) \le 0$\ \algorithmicthen\ continue\ \algorithmicendif\
		        %将$c_k$加入集合$\mathcal{VC}$\;
		    }
		}
		\If{$\mathcal{VC}$非空}
		{
		    $c^* = \argmaxl_{c \in \mathcal{VC}} S(\bm{x}^{(t)},c,j)$\;
    		$t = t + 1$\;
    		$\bm{x}^{(t)} \leftarrow \text{将} \bm{x}^{(t-1)} \text{中的} x_j  \text{替换为} c^*$\;
    		\If{$t \ge \gamma \cdot N $}
    		{
    		    \algorithmicreturn\ $\bm{x}^{(t)}$
    		}
    		%\algorithmicif\  $t \ge \gamma \cdot N $\ \algorithmicthen\   \algorithmicreturn\ $\bm{x}^{(t)}$\ \algorithmicendif\;
		}
		\eIf{$t > 0$}
		{
		    \algorithmicreturn\ $\bm{x}^{(t)}$
		}
		{
		    \algorithmicreturn\ None
		}
		%\algorithmicif\  $t > 0$\ \algorithmicthen \algorithmicreturn\ $\bm{x}^{(t)}$\ \algorithmicelse\ \algorithmicreturn\ None \algorithmicendif
	\AlgoBiCaption{针对依存分析器的黑盒攻击算法}{Black-box attack algorithm against dependency parsers.}
	\label{algo:attack}
	%\bicaption[algo:attack]{算法}{针对依存分析器的黑盒攻击算法}{Algo.$\!$}{Effect of different modules of BS-IT model.}
\end{algorithm}


\subsection{词重要性排序}[Word Importance Ranking]

在一个句子中，不同的词对于模型的预测结果会产生不同程度的影响，本章将这种影响的大小视为词的重要性，对句中词按重要性进行排序。
此前的方法通过将句中词逐个替换为未知标签并计算替换前后模型预测结果的改变获得词的重要性。\cite{li-etal-2016-visualizing,ren-etal-2019-generating}
针对依存分析任务，本章使用替换前后无标记依存正确率（Unlabled Attachment Score，简称UAS）和带标记依存正确率（Labled Attachment Score，简称LAS）的改变量作为衡量词重要性的分数。
具体来说，句子$\bm{x}$中词$x_i$的重要性为：
\begin{equation}
	\label{eq:word-importance}
	I(\bm{x},x_i) = \lambda_{arc}\Delta_\text{UAS}(\bm{x},\hat{\bm{x}_i}) + (1-\lambda_{arc})\Delta_\text{LAS}(\bm{x},\hat{\bm{x}_i}),
\end{equation}
其中$\bm{x} = x_1x_2\dots x_i\dots x_N$为原始句子，$\hat{\bm{x}_i} = x_1x_2\dots \text{UNK}\dots x_N$为将词$x_i$替换为特殊未知词标签UNK的修改后句子。
$\Delta_\text{UAS}(\bm{x},\hat{\bm{x}_i}) = \text{UAS}(F(\bm{x})) - \text{UAS}(F(\hat{\bm{x}_i})) $和$\Delta_\text{LAS}(\bm{x},\hat{\bm{x}_i}) = \text{LAS}(F(\bm{x})) - \text{LAS}(F(\hat{\bm{x}_i}))$分别表示修改前后UAS和LAS的改变量。
$\lambda_{arc}$为用于调节依存弧和标签之间相对重要性的系数。


\subsection{候选词生成}[Generation of Substitute Candidates]
\label{sec:gen-cand}

候选词生成是本章提出的攻击算法中重要的一步，生成的候选词的数量和质量决定了攻击时的搜索空间和对抗样本的质量。
本文第\ref{sec:chapter3-related-work}节中介绍了此前工作使用的基于预训练语言模型BERT生成候选词的方法，受到BERT本身词片段表示形式的制约，这种方法生成的候选词也受到了严重限制。
此外，与使用词片段向量作为输入的英文BERT不同，现存的中文BERT使用字向量作为输入，这种情况也使该方法无法直接应用到中文语义依存图分析模型的攻击中。
为了同时保证生成的候选词的数量和质量，本章首先使用四种候选词生成方法生成大量候选词，然后使用三种过滤方法过滤掉其中不合适的候选词。
此前的工作尝试了包括基于语言模型的\cite{zheng2020evaluating}、基于词向量的\cite{alzantot2018generating}、基于同义词的\cite{ren2019generating}和基于义原（Sememe）的\cite{zang2020word}生成方法。
这些方法各自存在不同的问题，前两类生成的候选词质量无法保证，而后两类生成候选词的数量受到限制。
为了解决这些问题，我们首先同时用这四类方法生成候选词集合，之后使用四种过滤方法过滤掉不合适的候选词，从而同时保证了候选词的质量和数量。

接下来首先具体介绍本章使用的四种候选词生成方法：

1.基于BERT的方法\cite{zheng-etal-2020-evaluating}。
本章提出的攻击算法能够同时攻击中文和英文依存分析模型。
由于目前中英文的BERT采用了不同类别的输入向量，这里将分别介绍中英文的情况。

针对英文，本章采取与第\ref{sec:chapter3-related-work}节中介绍的Zheng等人相同的方法，将原始句子中的词逐个遮盖，然后使用英文BERT基于其上下文预测词表中所有词出现在此上下文中的概率。
之后对这些词按照出现概率排序，选择前$k$个整词（没有被切分成片段的词）作为当前词的候选词。

针对中文，由于中文BERT采用字向量而非词片段向量作为输入，本章采用分别计算组成一个词的各个字在上下文中的出现概率，然后用多个字同时概率作为候选词概率的方式来生成候选词。
具体来说，假设当前目标词$w=\{c_1, c_2, \dots, c_N\}$由$N$个字组成。
本方法逐个将其中的每个字遮盖，利用中文BERT基于上下文预测每个可能的字出现在此处的概率。
将字$s_i$出现在$i$位置，替换字$c_i$的概率记为$p(c_i\rightarrow s_i)$。
则候选替换词$w'=\{s_1, s_2, \dots, s_N\}$的概率为$p(w\rightarrow w') = \prod_{i=0}^{N}p(c_i\rightarrow s_i)$。
然而由于本方法在每个位置预测的都是所有可能出现的字，全排列组合中的有些词可能是没有意义的。
为了避免将这种没有意义的词也作为候选词，本方法会对组合后的词使用中文词表进行过滤，只保留在中文词表中的有意义的词。
过滤后，对剩余的词按照$p(w\rightarrow w')$进行排序，选取其中前$k$个作为当前词的候选词。

2.基于词向量的方法\cite{alzantot-etal-2018-generating}。
该方法使用预训练的固定词向量，计算各词之间的词向量余弦相似度，目标词的$k$个最近的词作为其候选词。
需要注意的是，在一般的词向量中，距离近的词不仅有近义词，也有反义词。
这是因为一般的词向量训练方法只是根据词在上下文中的出现情况学习其向量表示，而同义词和反义词都容易出现在相同的上下文中。
为了解决这一问题，本章使用Mrksic等人\cite{mrksic-etal-2016-counter}提出的方法对预训练固定词向量进行预处理。
具体来说，该方法在预训练词向量中加入了来自近义词和反义词词典的约束，在保证词向量之间相对位置不变的同时缩短近义词向量间的距离，扩大反义词向量建的距离。
这种预处理使该方法生成的候选词更有可能是近义词，从而提高了其质量。
对于英文，该方法使用预处理过的GloVe词向量\cite{pennington-etal-2014-glove}计算余弦相似度。
对于中文，该方法首先Word2vec方法\cite{mikolov-etal-2013-distributed}在中文Gigawords语料\footnote{\url{https://catalog.ldc.upenn.edu/LDC2011T13}}上训练固定词向量，然后用上述方法对其进行预处理，最后计算余弦相似度。

3.基于近义词的方法\cite{ren-etal-2019-generating}。
该方法从近义词词典中获取目标词的近义词作为候选词。
对于英文，该方法使用WordNet\footnote{\url{https://wordnet.princeton.edu}}获取目标词的近义词。
对于中文，该方法使用哈工大同义词词林获取目标词的近义词。

4.基于义原的方法\cite{zang-etal-2020-word}。
Dong等人\cite{dong-etal-2006-hownet}于2006年提出了基于义原的语言知识库——知网（HowNet）。
义原在语言学中指最小的不可再分的语义单位， 对于每个候选词，该方法根据知网中定义的义原，收集词表中所有至少有一个义原与其重复的词作为其候选词。
例如，假设目标词为“中文”，其在知网中的的义原包括“中国”和“语言”，对于词表中的词“英文”，其在知网中的义原包括“英国”和“语言”。
由于“英文”的义原与“中文”的义原中都包含“语言”，该方法将“英文”作为“中文”的候选词。
知网中定义的义原包括中文和英文两部分，因此针对中英文方法都统一使用知网中定义的义原来获取其候选词。

在用上述方法获得大量候选词之后，本章依次使用以下三种过滤方法，将所有候选词中不合适的过滤掉：

1.词性过滤方法。
该方法过滤掉候选词中与目标词词性不同的，这是为了确保替换后句法结构不变。

%\textbf{语法检测过滤} \ \ 我们使用公开的语法检测工具\footnote{\url{https://pypi.org/project/language_tool}}过滤掉替换后会引入语法错误的候选词，从而进一步确保句法结构的不变性和语法的正确性。

2.词向量相似度过滤方法。
该方法使用词向量余弦相似度过滤掉与目标词相似度低于$\epsilon_w$的候选词。

3.困惑度过滤方法。
对于每个候选词$c \in \mathcal{C}$，该方法使用预训练的语言模型GPT-2计算原始句子$\bm{x}$和替换后句子$\bm{x}^c_{i}$的困惑度，定义困惑度增量为：
\begin{equation}
	\label{eq:ppl-inc}
	\Delta \text{ppl}(\bm{x},c,i)=\max(\text{ppl}(\bm{x}^c_{i})-\text{ppl}(\bm{x}), 0),
\end{equation}
其中$\bm{x}^c_{i}$为将原始文本$\bm{x}$的第$i$个词替换为$c$后的文本。
$\Delta\text{ppl}(\bm{x},c,i) > \epsilon_p$的候选词将被过滤掉。


\subsection{替换词搜索}[Best Substitute Searching]

在这一步，本章用贪心搜索策略按照目标词重要性由高到底搜索其候选词，找到合适的替换词。
为了保持句子的句法结构不变，在搜索中不允许替换代词、冠词、连词、数字、感叹词、限定疑问词和标点符号。
此外，为了控制修改词的个数，在实验中设置了最大允许修改百分比$\gamma$。%（实验中设为15\%）。

具体来说，给定句子$\bm{x}$，首先按照目标词重要性从高到低对其进行排序，并按此顺序进行搜索。
对每个目标词$x_i$，用其候选词集合$\mathcal{C}$中的每个候选词$c$构建一个对抗样本$\bm{x}^c_{i} = x_1x_2\dots c\dots x_N$，并计算目标分析器分别以$\bm{x}$和$\bm{x}^c_{i}$为输入时的准确率差值：

\begin{equation}
	\label{eq:mis-inc}
	S(\bm{x},c,i) =  \lambda_{arc}\Delta_\text{UAS}(\bm{x},\bm{x}^c_{i}) +
	 (1-\lambda_{arc})\Delta_\text{LAS}(\bm{x},\bm{x}^c_{i}),
\end{equation}
其中$\Delta_\text{UAS}(\bm{x},\bm{x}^c_{i}) = \text{UAS}(F(\bm{x})) - \text{UAS}(F(\bm{x}^c_{i})) $和$\Delta_\text{LAS}(\bm{x},\bm{x}^c_{i}) = \text{LAS}(F(\bm{x})) - \text{LAS}(F(\bm{x}^c_{i}))$分别为UAS和LAS的改变量。 
$\lambda_{arc}$是一个控制依存弧和标签相对重要性的系数。%，在实验中设为0.5。

如果没有一个候选词$c$使得$S(\bm{x},c,i) > 0$，换句话说，如果没有候选词能马上使准确率降低，则跳过这个目标词，开始搜索下一个目标词的候选词。
否则，就选择准确率该变量$S(\bm{x},c,i)$最大的候选词$c$，并用其替换$x_i$。
接着，如果该句子中已修改的词占比超过了$\gamma$，则停止搜索返回当前句子。
否则继续搜索下一个目标词的候选词。


\section{对抗样本攻击实验结果与分析}[Experiments and Analysis of Adversarial Attack]


\subsection{实验设置}[Experimental Settings]


\subsection{对抗样本攻击实验结果}[Results for Adversarial Attack]

我们在依存句法分析领域应用最广的宾州树库（Penn Treebank，PTB）上测试了我们的攻击算法，并与此前工作进行了对比。
我们选择了依存分析任务中两个具有代表性的分析器Biaffine分析器\cite{dozat2017deep}和Stack-Pointer分析器\cite{ma2018stack}作为攻击目标，其中前者是基于图的分析器，后者是基于转移的分析器。
在目前广泛应用的深度神经网络模型中，输入词向量往往对模型性能产生至关重要的影响。
为了测试不同类型的词表示作为输入时目标分析器的鲁棒性，我们选择了以下四种有代表性的词表示：

\textbf{GloVe}\cite{pennington2014glove}是一个常用的固定上下文无关词向量。

\textbf{RoBERTa}\cite{liu2019roberta}是一个预训练语言模型，其训练目标为掩码语言模型（masked language modeling，MLM），目标是通过上下文预测被遮盖的词。 该模型生成的是上下文相关子词（sub-word）向量。

\textbf{ELECTRA}\cite{clark2020electra}是另一个预训练语言模型，其训练目标为替换词检测（ replaced token detection），目标是预测被修改的输入文本中哪个词被修改过。
该模型生成的是上下文相关子词（sub-word）向量。

\textbf{ELMo}\cite{peters2018deep}是一个基于字母向量的预训练语言模型，其训练目标为双向语言模型。 

\begin{table}[h]
	\bicaption[tbl:eval-result]{}{自动评价和人工评价结果}{Table$\!$}{Automatic and human evaluation results.}
    \vspace{0.5em}\centering\wuhao
	\begin{tabular}{lccc}
		\toprule[1.5pt]
		\multirow{2}{*}{Model}& Automatic & \multicolumn{2}{c}{Human} \\
		\cmidrule(r){2-2} \cmidrule(r){3-4}
		& 困惑度 &  流畅性\% & 句法不变性\%  \\
		\midrule[1pt]
		Zheng et al. & 267.96 & 20 & 75 \\
		Ours &\bf 139.99 &\bf 80 &\bf 85  \\
		\bottomrule[1.5pt]
	\end{tabular}
\end{table}

\begin{table}[h]
	\bicaption[tbl:attack-cop]{}{PTB-SD-3.3.0-COP测试集上的结果}{Table$\!$}{Results on PTB-SD-3.3.0-COP test set.}
    \vspace{0.5em}\centering\wuhao
	\begin{tabular}{lccc}
		\toprule[1.5pt]
		模型& 原始UAS & 攻击后UAS & 攻击成功率\% \\
		\midrule[1pt]
		Zheng et al. & 95.52 & 88.69 & 51 \\
		Ours & 95.45 & 88.95 &  44 \\
		\bottomrule[1.5pt]
	\end{tabular}
\end{table}

表~\ref{tbl:attack-cop}中列出了我们的模型（\textbf{Ours}）与此前工作的对比。
由于Zheng等人对PTB的预处理与普遍使用的略有不同，我们为了与他们的结果进行对比，先用他们的处理方式生成了PTB-SD-3.3.0-COP数据集并在该数据集上与他们进行了对比。
实验结果表明我们的方法获得了更高的攻击成功率。
此外，我们的平均修改词数几乎只有他们的一半，这说明我们的攻击效率要显著高于他们。

为了进一步对比各攻击方法生成的对抗样本的质量，我们采用人工评价的方法，从句法结构不变性和语法正确性两方面对样本质量进行评价。
为了评价句法结构不变性，我们随机选择了100个句子和对应的对抗样本，让三位人类评价者判断修改后是否改变了句法结构。
结果显示其中87\%的句子句法结构都是不变的。而Zheng等人进行的相同人工评价结果显示他们的对抗样本中仅75\%的句子句法结构不变。
为了评价语法正确性，我们随机挑选了100个句子，将我们和他们模型生成的对抗样本同时提供给人类评价者，让其选择哪个样本更好的保证了语法正确性（允许选择二者语法正确性同样好）。
结果显示对于56\%的句子我们的对抗样本更好，对于19\%的句子他们的更好，剩余25\%二者同样好。

\begin{table}[htbp]
	\bicaption[tbl:attack-main]{}{PTB-SD-3.3.0测试集上的结果}{Table$\!$}{Experimental results on PTB-SD-3.3.0 test set.}
    \vspace{0.5em}\centering\wuhao
	\begin{tabular}{llccccc}
		\toprule[1.5pt]
		\multirow{2}{*}{分析器}&\multirow{2}{*}{输入}& \multicolumn{2}{c}{原始结果} & \multicolumn{2}{c}{攻击后结果} & \multirow{2}{*}{攻击成功率\%} \\
		\cmidrule(r){3-4} \cmidrule(r){5-6}
		& & UAS & LAS & UAS & LAS \\
		\midrule[1pt]
		\multirow{4}{*}{ Biaffine} & Glove &95.36 & 93.49 &88.69 &85.09 &55.3 \\
		& ELMo  &96.29 &94.51  &90.70 &87.67 &47.5 \\
		& ELECTRA &97.12 & 95.38 &91.05 &87.79 &50.6 \\
		& RoBERTa &97.09 & 95.41 &92.14 &89.42 &46.1 \\
		\hline
		\multirow{4}{*}{ Stack-Pointer} & Glove &94.93 & 93.05 &88.26 &84.64 &52.6 \\
		& ELMo    &95.69 & 93.77 &89.57 &86.49 &46.8 \\
		& ELECTRA &96.94 & 95.19 &90.69 &87.47 &50.3 \\
		& RoBERTa &96.93 & 95.20 &91.58 &88.84 &45.1 \\
		\bottomrule[1.5pt]
	\end{tabular}
\end{table}

为了方便此后的工作进行对比，我们使用PTB普遍的预处理方式生成的PTB-SD-3.3.0数据集，并在该数据集上进行了大量实验，对比了两类分析器和四类词向量在我们的攻击算法下的性能，结果见表~\ref{tbl:attack-main}。
结果显示基于图的Biaffine分析器在输入向量相同的情况下普遍好于基于转移的Stack-Pointer分析器，而二者面对对抗样本攻击时鲁棒性差距不大。
在四种输入表示中，ELECTRA在原始文本作为输入时取得最好实验结果，RoBERTa次之，GloVe最差。
但在面对对抗样本攻击时，RoBERTa表现最好，ELMo也表现出了近似的鲁棒性，而ELECTRA则变现的很不好，其攻击成功率仅次于GloVe。
我们推测这可能是因为ELECTRA的训练目标是预测句中哪个词被修改过，而这种训练目标使得其将很多正确的替换词也视为错误，从而降低了它的鲁棒性。


\begin{table}[ht]
	\bicaption[tbl:oov-oot-result]{}{OOV和OOT词实验结果}{Table$\!$}{OOV and OOT test results.}
    \vspace{0.5em}\centering\wuhao
	\begin{tabular}{lccccccccc}
		\toprule[1.5pt]
		\multirow{2}{*}{词表}& \multicolumn{4}{c}{原始结果} & \multicolumn{4}{c}{攻击后结果} & \multirow{2}{*}{攻击成功率\%} \\
		\cmidrule(r){2-5} \cmidrule(r){6-9}
		&UAS &LAS &OOV &OOT &UAS &LAS &OOV &OOT \\
		\midrule[1pt]
		50k  &95.36 &93.49 &2  &24 &87.58 &83.73 &972 &1285 &59.5 \\
		400k &95.36 &93.49 &0  &15 &88.69 &85.09 &2       &906  &55.3 \\
		400k (T.) &95.36 &93.49 &0  &8  &90.06 &87.26 &0 &0 &45.5 \\
		\bottomrule[1.5pt]
	\end{tabular}
\end{table}


为了探究未登录（Out-of-Vocabulary，OOV）词和未在训练集出现（Out-of-Training，OOT）词对于对抗样本攻击的影响，我们用Biaffine分析器和GloVe向量进行了实验，在训练时使用不同大小的词表，实验结果见表~\ref{tbl:oov-oot-result}。
其中\textbf{Base}模型词表大小为39073，而\textbf{Large}模型词表大小为371025。
\textbf{Base (T.)}表示在对\textbf{Base}模型攻击时只允许从训练集中出现过的词中搜索替换词。
而相应的攻击前后未登录词和未在训练集出现词的数量见表~\ref{tbl:oov-oot-num}。
对比\textbf{Base}和\textbf{Large}模型被攻击前后的实验结果及未登录词数量统计，我们有理由认为对抗样本中出现的未登录词会引起模型预测错误。
而更大的词表能通过降低未登录词出现的可能性从而有效增强模型的鲁棒性。
此外，通过对比\textbf{Base}和\textbf{Base (T.)}的结果，我们可以认为未在训练集中出现过的词也会降低模型预测的准确率。

针对未在训练集中出现过的词，一个可能的解决方案是对抗学习，即使用对抗攻击算法对训练数据生成对抗样本，然后用原始训练数据和对抗样本混合训练分析器。
此前的工作\cite{zheng2020evaluating}已证明此方法的有效性。
然而在现实情况下我们很难在训练时就获知对抗攻击算法，而且使用这种对抗学习也有使得模型过拟合到对抗样本的风险。
因此我们基于上文实验的观察结果，提出几种不需要对抗攻击算法就能增强模型鲁棒性的方法。

表~\ref{tbl:attack-increase}中列出了使用上述策略后模型面对对抗样本攻击的实验结果。
结果显示这三种策略都能有效提高模型鲁棒性，降低攻击成功率。
当这三者结合起来的时候效果最好。
由于我们在训练过程中没有使用任何对抗样本，这三种策略也没有使模型过拟合到某种特定攻击的风险。
这部分工作已投往AAAI 2021，后续计划将该攻击算法的目标扩展到语义依存图分析。


\begin{table}[h]
	\bicaption[tbl:transfer-test-biaffine]{}{Biaffine分析器作为源模型的对抗样本传递性实验结果}{Table$\!$}{Results in the transferability test with Biaffine parser as the source parser.}
    \vspace{0.5em}\centering\wuhao
	\begin{tabular}{lcccccc}
		\toprule[1.5pt]
		\multirow{2}{*}{源词向量}& \multirow{2}{*}{跨随机种子} & \multirow{2}{*}{跨模型} & \multicolumn{4}{c}{跨词向量} \\
		\cline{4-7}
		& &  & GloVe & ELMo & ELECTRA & RoBERTa \\
		\midrule[1pt]
		GloVe &45.0  &40.3  &\bf 55.3 &27.7 &27.2 &25.2 \\
		ELMo &36.3  &35.6  &28.0 &\bf 47.5 &29.6 &27.2 \\
		ELECTRA &34.8  &40.2  &27.1 &28.8 &\bf 50.6 &29.2 \\
		RoBERTa &39.8  &35.0  &25.5 &27.9 &29.8 &\bf 46.1 \\
		\bottomrule[1.5pt]
	\end{tabular}
\end{table}

\begin{table}[h]
	\bicaption[tbl:transfer-test-biaffine]{}{Stack-Pointer分析器作为源模型的对抗样本传递性实验结果}{Table$\!$}{Results in the transferability test with Stack-Pointer parser as the source parser.}
    \vspace{0.5em}\centering\wuhao
	\begin{tabular}{lcccccc}
		\toprule[1.5pt]
		\multirow{2}{*}{源词向量}& \multirow{2}{*}{跨随机种子} & \multirow{2}{*}{跨模型} & \multicolumn{4}{c}{跨词向量} \\
		\cline{4-7}
		& &  & GloVe & ELMo & ELECTRA & RoBERTa \\
		\midrule[1pt]
		GloVe &41.1  &40.8  &\bf 52.6 &25.8 &25.7 &23.7 \\
		ELMo &36.0  &34.8  &26.5 &\bf 46.8 &27.0 &26.6 \\
		ELECTRA &35.3  &33.7  &24.4 &28.5 &\bf 50.3 &29.9 \\
		RoBERTa &41.1  &38.8  &24.2 &26.0 &29.7 &\bf 45.1 \\
		\bottomrule[1.5pt]
	\end{tabular}
\end{table}


\subsection{基于模型融合的鲁棒性提升方法}[Robustness Increasing Approach Based on Model Ensemble]

\begin{table}[htbp]
	\bicaption[tbl:embed-ens-result]{}{跨词向量模型融合实验结果}{Table$\!$}{Cross-embedding ensemble results.}
    \vspace{0.5em}\centering\wuhao
	\begin{tabular}{lccccc}
		\toprule[1.5pt]
		\multirow{2}{*}{词向量}& \multicolumn{2}{c}{原始结果} & \multicolumn{2}{c}{攻击后结果} & \multirow{2}{*}{攻击成功率\%} \\
		\cmidrule(r){2-3} \cmidrule(r){4-5}
		& UAS & LAS & UAS & LAS & \\
		\midrule[1pt]
		\multicolumn{6}{c}{Biaffine} \\
		\hline
		RoBERTa        &97.09 & 95.41 &92.14 &89.42 &46.1 \\
		+GloVe     &97.16 & 95.55 &92.39 &89.77 &43.8 \\
		+ELMo   &97.20 & 95.58 &92.53 &89.97 &42.5 \\
		+ELECTRA &\bf97.25 &\bf95.63 &\bf92.73 &\bf90.12 &\bf41.5 \\
		\hline
		\multicolumn{6}{c}{Stack-Pointer} \\
		\hline
		RoBERTa        &96.93 & 95.20 &91.58 &88.84 &45.1 \\
		+GloVe     &97.01 & 95.32 &92.15 &89.49 &43.4 \\
		+ELMo   &96.98 & 95.26 &\bf 92.28 &89.62 &42.3 \\
		+ELECTRA &\bf 97.14 &\bf 95.45 &92.27 &\bf 89.64 &\bf 41.5 \\
		\bottomrule[1.5pt]
	\end{tabular}
\end{table}


\subsection{基于对抗样本训练的鲁棒性提升方法}[Robustness Increasing Approach Based on Adversarial Training]

\begin{table}[htbp]
	\bicaption[tbl:adv-train-result]{}{对抗样本学习实验结果}{Table$\!$}{Adversarial training results.}
    \vspace{0.5em}\centering\wuhao
	\begin{tabular}{lccccc}
		\toprule[1.5pt]
		\multirow{2}{*}{词向量}& \multicolumn{2}{c}{原始结果} & \multicolumn{2}{c}{攻击后结果} & \multirow{2}{*}{攻击成功率\%} \\
		\cmidrule(r){2-3} \cmidrule(r){4-5}
		& UAS & LAS & UAS & LAS & \\
		\midrule[1pt]
		\multicolumn{6}{c}{Biaffine} \\
		\hline
		%GloVe &95.36 & 93.49 &88.69 &85.09 &55.3 \\
		GloVe &95.32 (-0.04) & 93.45 (-0.04) &91.90 (+3.21) &89.34 (+4.25) &38.5 (-16.8) \\
		%ELMo &96.29 &94.51  &90.70 &87.67 &47.5 \\
		ELMo &96.17 (-0.12) &94.37 (-0.14) &93.49 (+2.79) &91.03 (+3.36) &33.2 (-14.3) \\
		%ELECTRA &97.12 & 95.38 &91.05 &87.79 &50.6 \\
		ELECTRA &96.96 (-0.16) & 95.23 (-0.15) &95.03 (+3.98) &92.58 (+4.79) &33.4 (-17.2) \\
		%RoBERTa &97.09 & 95.41 &92.14 &89.42 &46.1 \\
		RoBERTa &97.03 (-0.06) & 95.30 (-0.11) &95.30 (+3.16) &93.02 (+3.60) &29.5 (-16.6) \\
		\hline
		\multicolumn{6}{c}{Stack-Pointer} \\
		\hline
		%GloVe &94.93 & 93.05 &88.26 &84.64 &52.6 \\
		GloVe &94.92 (-0.01) & 93.04 (-0.01) &91.58 (+3.32) &88.82 (+4.18) &36.2 (-16.4) \\
		%ELMo &95.69 & 93.77 &89.57 &86.49 &46.8 \\
		ELMo &95.75 (+0.06) & 93.81 (+0.04) &92.64 (+3.07) &90.02 (+3.53) &34.1 (-12.7) \\
		%ELECTRA &96.94 & 95.19 &90.69 &87.47 &50.3 \\
		ELECTRA &96.83 (-0.11) & 95.04 (-0.15) &94.53 (+3.84) &91.96 (+4.49) &34.2 (-16.1) \\
		%RoBERTa &96.93 & 95.20 &91.58 &88.84 &45.1 \\
		RoBERTa &96.80 (-0.13) & 95.01 (-0.19) &95.10 (+3.52) &92.83 (+3.99) &29.1 (-16.0) \\
		\bottomrule[1.5pt]
	\end{tabular}
\end{table}

\iffalse
\begin{table}[htbp]
	\bicaption[tbl:adv-train-result]{}{对抗样本学习实验结果}{Table$\!$}{Adversarial training results.}
    \vspace{0.5em}\centering\wuhao
	\begin{tabular}{lccccc}
		\toprule[1.5pt]
		\multirow{2}{*}{词向量}& \multicolumn{2}{c}{原始结果} & \multicolumn{2}{c}{攻击后结果} & \multirow{2}{*}{攻击成功率\%} \\
		\cmidrule(r){2-3} \cmidrule(r){4-5}
		& UAS & LAS & UAS & LAS & \\
		\midrule[1pt]
		\multicolumn{6}{c}{Biaffine} \\
		\hline
		GloVe &95.36 & 93.49 &88.69 &85.09 &55.3 \\
		GloVe* &95.32 & 93.45 &91.90 &89.34 &38.5 \\
		\hline
		ELMo &96.29 &94.51  &90.70 &87.67 &47.5 \\
		ELMo* &96.17 &94.37  &93.49 &91.03 &33.2 \\
		\hline
		ELECTRA &97.12 & 95.38 &91.05 &87.79 &50.6 \\
		ELECTRA* &96.96 & 95.23 &95.03 &92.58 &33.4 \\
		\hline
		RoBERTa &97.09 & 95.41 &92.14 &89.42 &46.1 \\
		RoBERTa* &97.03 & 95.30 &95.30 &93.02 &29.5 \\
		\hline
		\multicolumn{6}{c}{Stack-Pointer} \\
		\hline
		GloVe &94.93 & 93.05 &88.26 &84.64 &52.6 \\
		GloVe* &94.92 & 93.04 &91.58 &88.82 &36.2 \\
		\hline
		ELMo &95.69 & 93.77 &89.57 &86.49 &46.8 \\
		ELMo* &95.75 & 93.81 &92.64 &90.02 &34.1 \\
		\hline
		ELECTRA &96.94 & 95.19 &90.69 &87.47 &50.3 \\
		ELECTRA* &96.83 & 95.04 &94.53 &91.96 &34.2 \\
		\hline
		RoBERTa &96.93 & 95.20 &91.58 &88.84 &45.1 \\
		RoBERTa* &96.80 & 95.01 &95.10 &92.83 &29.1 \\
		\bottomrule[1.5pt]
	\end{tabular}
\end{table}
\fi

\section{本章小结}[Conclusions]


% Local Variables:
% TeX-master: "../thesis"
% TeX-engine: xetex
% End: